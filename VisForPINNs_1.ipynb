{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18595a64",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; font-size: 20px;\"> \n",
    "    <h1> VisForPINNs </h1>\n",
    "</div>\n",
    "\n",
    "<div style=\"text-align: center;\"> \n",
    "    <h1> Visualization for Understanding Physics Informed Neural Networks</h1>\n",
    "</div>\n",
    "\n",
    "<div style=\"text-align: center; font-size: 8px;\">\n",
    "    <h1> By: \n",
    "        <a href=\"https://www.itwm.fraunhofer.de/en/departments/tv/staff/viny_saajan_victor.html\" style=\"color: blue;\">Viny      Saajan Victor</a>,\n",
    "        <a href=\"https://www.itwm.fraunhofer.de/en/departments/tv/staff/manuel-ettmueller.html\" style=\"color: blue;\">Manuel Ettmüller</a>,\n",
    "        <a href=\"https://www.itwm.fraunhofer.de/en/departments/tv/staff/andre-schmeisser.html\" style=\"color: blue;\">Dr. Andre Schmeißer</a>,\n",
    "        <a href=\"https://vis.uni-kl.de/team/leitte/\" style=\"color: blue;\">Prof. Dr. Heike Leitte</a>, and\n",
    "        <a href=\"https://www.itwm.fraunhofer.de/en/departments/tv/staff/simone-gramsch.html\" style=\"color: blue;\">Prof. Dr. Simone Gramsch</a>\n",
    "    </h1>\n",
    "</div>\n",
    "\n",
    "<div style=\"text-align: center; font-size: 8px;\">\n",
    "    <h1> July 21, 2023 </h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e813b0a",
   "metadata": {},
   "source": [
    "## 1. Introduction:\n",
    "\n",
    "In recent years, the field of machine learning (ML) has experienced remarkable advancements primarily due to its capacity to uncover patterns and structures within provided data. Among the various categories of machine learning, supervised learning stands out as a significant approach with diverse applications, including classification, regression, and more. In a typical supervised learning scenario, a model is trained using labeled data, where input data is accompanied by corresponding output labels. The objective is to establish a relationship between the input data and the desired output labels. These models are often referred to as \"data-driven\" since their effectiveness relies on the quality and quantity of the labeled training data. By learning from these labeled examples, the models gain the ability to identify patterns and make predictions or classifications on new, unseen data, thus demonstrating their generalization capabilities.  \n",
    "<br>\n",
    "<br>\n",
    "<figure>\n",
    "  <img src=\"DD_ML_1.png\" alt=\"Data Driven Machine Learning\"/>\n",
    "  <figcaption></figcaption>\n",
    "</figure>\n",
    "\n",
    "<div style=\"text-align: center;\"> \n",
    "    The image shows the information flow in data-driven machine learing. Image adopted from [1]\n",
    "</div>\n",
    "\n",
    "Insufficient data poses limitations for data-driven ML models. When the available training data fails to adequately represent the variability and capture the system behavior being examined, the resulting ML model will exhibit poor performance. Moreover, if the data contains noise and there are no means to impose constraints on the model other than through the data itself, the model's reliability will be compromised. Additionally, the model's explainability will be reduced, as it primarily focuses on mapping input-output data without providing insightful explanations.To address these limitations, one approach is to integrate prior knowledge into the machine learning process. This research field is commonly referred to as \"Informed Machine Learning[1].\" By incorporating prior knowledge, the ML models can overcome the challenges posed by insufficient data, noisy inputs, and limited explainability.\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<figure>\n",
    "  <img src=\"IML.png\" alt=\"Informed Machine Learning\"/>\n",
    "  <figcaption></figcaption>\n",
    "</figure>\n",
    "\n",
    "<div style=\"text-align: center;\"> \n",
    "    The image shows the information flow in data-driven machine learing and informed machine learning. Image adopted from [1]\n",
    "</div>\n",
    "\n",
    "There are various ways to represent prior knowledge, and it can be integrated into different stages of the machine learning pipeline depending on data availability, knowledge sources, and application scenarios.\n",
    "<br>\n",
    "<br>\n",
    "<figure>\n",
    "  <img src=\"Sankey.png\" alt=\"Knowledge Integration\"/>\n",
    "  <figcaption></figcaption>\n",
    "</figure>\n",
    "\n",
    "<div style=\"text-align: center;\"> \n",
    "    The image displays the sources, representations and of the prior knowledge and their integration to ML pipeline. Image adopted from [1]\n",
    "</div>\n",
    "<br>\n",
    "<br>\n",
    "<div style=\"text-align: center; font-size: 10px; color: green;\"> \n",
    "    <h1> Physics Informed Neural Networks (PINNs) </h1>\n",
    "</div>\n",
    "<br>\n",
    "Physics-informed neural networks (PINNs) are neural networks that incorporate prior scientific knowledge, such as differential equations, into the learning algorithm of the machine learning pipeline. These networks jointly learn to fit the training data while reducing the residual of the governing differential equations that describe the underlying physics of the model being examined. This process effectively constrains the model to adhere to the known physics laws. \n",
    "<br>\n",
    "<figure>\n",
    "  <img src=\"Sankey_PINN.png\" alt=\"Knowledge Integration in PINNs\"/>\n",
    "  <figcaption></figcaption>\n",
    "</figure>\n",
    "<div style=\"text-align: center;\"> \n",
    "    The image displays the source, representation and the integration of Knowledge in PINNs. Image adopted from [1]\n",
    "</div>\n",
    "\n",
    "PINNs are utilized for solving a range of equations, including ordinary differential equations (ODEs), partial differential equations (PDEs), fractional equations (FEs), integro-differential equations (IDEs), and stochastic differential equations (SDEs). The focus of this article is specifically on the application of PINNs for solving ODEs.\n",
    "\n",
    "## 2. Application : Ordinary Differential Equations for the Simulation of Melt Spinning Processes\n",
    "\n",
    "Melt spinning is a manufacturing process employed for the production of industrial fibers. In this process, a molten polymer is transformed into continuous filament fibers by extruding it through small openings known as spinnerets. These fibers are utilized in various industries, including textiles, automotive, and construction, owing to their advantageous attributes such as strength, durability, wrinkle resistance, and moisture-wicking capabilities. Optimizing the production process while maintaining the desired quality involves analyzing different properties of the fibers along their length. However, achieving real-time analysis is challenging due to the stochastic nature of the spinning processes. Consequently, modeling spinning processes often entails a combination of differential equations that describe the fiber properties. Furthermore, specific fiber properties remain fixed at the start and end positions of the fibers due to the process conditions resulting in differential equations with boundary conditions.\n",
    "\n",
    "In our analysis, we focus on iso-thermal uniaxial spinning as our specific use case. We examine a straight line fiber that extends between points $r_a$ and $r_b$, with a total fiber length of $L$. The system of ordinary differential equations (ODEs) governing the velocity ($u$) and tension ($N$) along the fiber length is expressed as follows:\n",
    "<br>\n",
    "<div style=\"text-align: center; font-size: 10px; color: black;\"> \n",
    "    <h1>$\\frac{du}{dx} = \\frac{u_0 u L N \\rho}{3 \\mu}$</h1>\n",
    "    <h1>$\\frac{dN}{dx} = \\frac{du}{dx} - \\frac{g r_0 e g_y \\tau_y}{u u_0^2}$</h1>\n",
    "</div>\n",
    "<br>\n",
    "<div style=\"text-align: center; font-size: 12px; color: black;\"> \n",
    "    $x \\in [0,1]$ and $L = \\frac{r_b - r_a}{\\lVert r_b - r_a \\rVert}$\n",
    "    <br>\n",
    "    <br>\n",
    "    with boundary values $u(x=0) = u_{in}$ and $u(x=1) = u_{out}$\n",
    "</div>\n",
    "\n",
    "## 3. Learning Objective\n",
    "As mentioned above, we incorporate the scientific knowlegde represented as differential equations into the loss function of the network. The loss function of the PINN for solving the above system of ode comprises of three terms:\n",
    "<br>\n",
    "<div style=\"text-align: center; font-size: 14px; color: black;\"> \n",
    "    $Loss_{pinn} = Loss_{data} + Loss_{boundary} + Loss_{ode\\_residual}$\n",
    "    <br>\n",
    "    <br>\n",
    "    where $Loss_{data} = \\frac{1}{N_{d}} \\sum_{i=1}^{N_{d}} \\frac{|u(x_d^i) - \\hat{u}(x_d^i)|^2 + |N(x_d^i) - \\hat{N}(x_d^i)|^2}{2}$\n",
    "    <br>\n",
    "    <br>\n",
    "    $ Loss_{boundary} = \\frac{1}{N_{b}} \\sum_{i \\in \\{0, 1\\}} |u(x_b^i) - \\hat{u}(x_b^i)|^2$\n",
    "</div>\n",
    "<br>\n",
    "<br>\n",
    "<div style=\"text-align: center; font-size: 14px; color: black;\">\n",
    "    $ Loss_{ode\\_residual} = \\frac{1}{N_{r}} \\sum_{i=1}^{N_{r}} \\frac{(\\frac{d\\hat{u}}{dx}(x_r^i) - \\frac{u_0 * \\hat{u}(x_r^i) * L * \\hat{N}(x_r^i) *  \\rho}{3 \\mu})^2 + (\\frac{d\\hat{N}}{dx}(x_r^i) - \\frac{d\\hat{u}}{dx}(x_r^i) + \\frac{g * r_0 * eg_y * \\tau_y}{\\hat{u}(x_r^i) * u_0^2})^2}{2}$\n",
    "</div>\n",
    "\n",
    "## 4. Building PINN Model and Visualizing the Results:\n",
    "\n",
    "Now, let's proceed to construct a Physics-Informed Neural Network (PINN) for the isothermal melt spinning process described and compare it with a data-driven network.\n",
    "To ensure consistency, we have selected identical architectures and activation functions for both networks. We have designed a network comprising three hidden layers, each consisting of 50 neurons. The activation function chosen for both networks is the hyperbolic tangent (tanh) function. For the data-driven network, we train it using $Loss_{data}$, which involves calculating the mean squared error (MSE) between the predicted and actual values. On the other hand, to train the PINN, we utilize $Loss_{boundary}$ and $Loss_{ode\\_residual}$, as described in the previous section. In $Loss_{ode\\_residual}$, we require the first-order derivative of the solution, which is calculated using the auto-differentiation function provided by the deep learning library. Below is the code snippet that demonstrates the implementation using TensorFlow:\n",
    "\n",
    "```python\n",
    "def loss_function(x_b, u_b, x_r):\n",
    "    # claculate the ode residual\n",
    "    x_r = tf.convert_to_tensor(x, dtype = tf.float32)\n",
    "    with tf.GradientTape(persistent = True) as tp:\n",
    "        tp.watch(x_r)\n",
    "        y_pred = PINN.predict(x_r)\n",
    "        u = y_pred[:, 0:1]\n",
    "        N = y_pred[:, 1:]\n",
    "    du = tp.gradient(u, x)\n",
    "    dN = tp.gradient(N, x)\n",
    "    del tp\n",
    "        \n",
    "    u_residual = du - ((u_typ * L * N * rho * u) / (3 * mu))\n",
    "    N_residual = dN - du + ((g * r_0) / (u * u_typ * u_typ)) * (eg_y * tau_y) * L\n",
    "        \n",
    "    loss_ode_residual =  tf.reduce_mean(tf.square(u_residual)) + tf.reduce_mean(tf.square(N_residual))\n",
    "    loss_boundary = tf.reduce_mean(tf.square(x_b - u_b))\n",
    "        \n",
    "    loss_total = boundary_loss_weight * loss_boundary + ode_residua_loss_weight * loss_ode_residual\n",
    "    return loss_total\n",
    "\n",
    "def train_model(x_b, u_b, x_r):\n",
    "    with tf.GradientTape(persistent = True) as tp:\n",
    "        loss = self.loss_function(x_b, u_b, x_r)\n",
    "    grad = tp.gradient(loss, PINN.trainable_params)\n",
    "    optimizer.apply_gradients(zip(grad, PINN.trainable_params))\n",
    " ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "dbd5f341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8050/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x28d1268cc08>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.graph_objects as go\n",
    "from jupyter_dash import JupyterDash\n",
    "from dash import dcc\n",
    "from dash import html\n",
    "from dash.dependencies import Input, Output, State\n",
    "import pandas as pd\n",
    "\n",
    "gt_data = pd.read_csv('ground_truth_single_eq.csv')\n",
    "gt_data = gt_data.rename(columns={'grid_points': 'grid points', 'solution_u': 'u(x)', 'solution_N': 'N(x)'})\n",
    "\n",
    "pinn_data = pd.read_csv('pinn_single_eq.csv')\n",
    "\n",
    "dd_data = pd.read_csv('data_single_eq.csv')\n",
    "dd_data.insert(loc=0, column='grid points', value=gt_data['grid points'])\n",
    "\n",
    "figure_u = go.Figure()\n",
    "figure_N = go.Figure()\n",
    "\n",
    "figure_u.add_trace(go.Scatter(x=gt_data['grid points'], y=gt_data['u(x)'],\n",
    "                    mode='lines',\n",
    "                    name='ground-truth'))\n",
    "figure_u.add_trace(go.Scatter(x=gt_data['grid points'], y=pinn_data['u(x)'],\n",
    "                    mode='lines',\n",
    "                    name='pinn'))\n",
    "\n",
    "figure_u.update_layout(xaxis=dict(range=[0, 1.05]))\n",
    "\n",
    "figure_N.add_trace(go.Scatter(x=gt_data['grid points'], y=gt_data['N(x)'],\n",
    "                    mode='lines',\n",
    "                    name='ground-truth'))\n",
    "figure_N.add_trace(go.Scatter(x=gt_data['grid points'], y=pinn_data['N(x)'],\n",
    "                    mode='lines',\n",
    "                    name='pinn'))\n",
    "\n",
    "figure_N.update_layout(xaxis=dict(range=[0, 1.05]))\n",
    "\n",
    "app = JupyterDash(__name__)\n",
    "app.layout = html.Div(\n",
    "    children=[\n",
    "        html.Div(\n",
    "            children=[\n",
    "                html.Div(\n",
    "                    children=[\n",
    "                        dcc.Interval(id=\"animate\", interval=250, disabled=True),\n",
    "                        html.H1(children='grid-points range used to generate training data',\n",
    "                                                style={\"text-align\": \"center\", 'fontSize': 21, \"font-weight\": \"bold\"}),\n",
    "                        html.Button(\"Play/Stop\", id=\"play\"),\n",
    "                        dcc.Slider(\n",
    "                        id='slider',\n",
    "                        min=0.0,\n",
    "                        max=1.0,\n",
    "                        step=0.1,\n",
    "                        value=0.0,\n",
    "                        )\n",
    "                    ], #end here\n",
    "                    style={ \"display\": \"inline-block\", \"width\": \"50%\", 'position': 'relative', 'left': '200px'}\n",
    "                )\n",
    "            ]\n",
    "        ),\n",
    "        html.Div(\n",
    "            children=[\n",
    "                html.Div(\n",
    "                    children=[\n",
    "                        dcc.Graph(id = \"fig_u\", figure=figure_u)\n",
    "                    ],\n",
    "                    style={\"display\": \"inline-block\", \"width\": \"50%\"},\n",
    "                ),\n",
    "                html.Div(\n",
    "                    children=[\n",
    "                        dcc.Graph(id = \"fig_N\", figure=figure_N)\n",
    "                    ],\n",
    "                    style={\"display\": \"inline-block\", \"width\": \"50%\"},\n",
    "                ),\n",
    "            ]\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "#Define callback to update graph\n",
    "@app.callback(\n",
    "    [Output('fig_u', 'figure'),\n",
    "     Output('fig_N', 'figure'),\n",
    "     Output(\"slider\", \"value\")],\n",
    "    [Input(\"animate\", \"n_intervals\"),\n",
    "     Input(\"slider\", \"value\")]\n",
    ")\n",
    "def update_figure(interval, value):\n",
    "    #print('value', value)\n",
    "    #print('interval', interval)\n",
    "    if interval != None:\n",
    "        figure_u.data = [figure_u.data[0], figure_u.data[1]]\n",
    "        figure_N.data = [figure_N.data[0], figure_N.data[1]]\n",
    "        index = interval%10\n",
    "        if index != 0:\n",
    "            #index = interval%10\n",
    "            index = round(index * 2)\n",
    "        else:\n",
    "            index = 20\n",
    "        #print('index', index)\n",
    "        value = index/20\n",
    "        #print('value', value)\n",
    "        df = gt_data[gt_data['grid points'] <= value]\n",
    "        figure_u.add_trace(go.Scatter(x=df['grid points'], y=df['u(x)'], mode='markers', name='training data'))\n",
    "        figure_N.add_trace(go.Scatter(x=df['grid points'], y=df['N(x)'], mode='markers', name='training data'))\n",
    "        figure_u.add_trace(go.Scatter(x=gt_data['grid points'], y=dd_data.iloc[:, index-1], mode='lines', name='ddnn'))\n",
    "        figure_N.add_trace(go.Scatter(x=gt_data['grid points'], y=dd_data.iloc[:, index], mode='lines', name='ddnn'))\n",
    "    return figure_u, figure_N, value\n",
    "\n",
    "@app.callback(\n",
    "    Output(\"animate\", \"disabled\"),\n",
    "    Input(\"play\", \"n_clicks\"),\n",
    "    State(\"animate\", \"disabled\"),\n",
    ")\n",
    "def toggle(n, playing):\n",
    "    if n:\n",
    "        return not playing\n",
    "    return playing\n",
    "        \n",
    "\n",
    "app.run_server(mode='inline', port=8050)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d233fb98",
   "metadata": {},
   "source": [
    "## 5. Convergence:\n",
    "\n",
    "Previously, we observed that the Physics-Informed Neural Network (PINN) can accurately predict the solution to an ordinary differential equation (ODE) with minimal error, even without any training data. Now, let's delve deeper and analyze how the convergence behavior of PINN compares to that of a data-driven neural network. To conduct this analysis, we chose several optimizers, namely adam, sgd, rmsprop, and lbfgs, and trained our models using different learning rates. We then generated an animation that demonstrates the results of this training process over 500 epochs. You can utilize the drop-down menu to switch between optimizers, learning rates, and observe their respective convergence patterns.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "b4bf86a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dash is running on http://127.0.0.1:3004/\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:3004/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x28d120abc88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler_data = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler_pinn = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "#rms_prop lbfgs = 5.517198\n",
    "\n",
    "#lr=0.001\n",
    "data_loss_adam_001 = pd.read_csv('data_loss_adam.csv')\n",
    "data_loss_adam_001 = data_loss_adam_001[1:]\n",
    "data_loss_adam_001['epoch'] = np.arange(499) + 1\n",
    "data_loss_adam_001['loss'] = np.log(data_loss_adam_001['loss'])\n",
    "\n",
    "#lr=0.01\n",
    "data_loss_adam_01 = pd.read_csv('data_loss_lr_0.01_7.652751e-07.csv')\n",
    "data_loss_adam_01 = data_loss_adam_01[1:]\n",
    "data_loss_adam_01['epoch'] = np.arange(499) + 1\n",
    "data_loss_adam_01['loss'] = np.log(data_loss_adam_01['loss'])\n",
    "\n",
    "#lr=0.1\n",
    "data_loss_adam_1 = pd.read_csv('data_loss_lr_0.1_1.6185334.csv')\n",
    "data_loss_adam_1 = data_loss_adam_1[1:]\n",
    "data_loss_adam_1['epoch'] = np.arange(499) + 1\n",
    "data_loss_adam_1['loss'] = np.log(data_loss_adam_1['loss'])\n",
    "\n",
    "data_loss_adam_after_lbfgs = pd.read_csv('data_loss_adam_after_lbfgs.csv')\n",
    "data_loss_adam_after_lbfgs = data_loss_adam_after_lbfgs[1:]\n",
    "data_loss_adam_after_lbfgs['epoch'] = np.arange(499) + 2\n",
    "data_loss_adam_after_lbfgs['loss'] = np.log(data_loss_adam_after_lbfgs['loss'])\n",
    "\n",
    "# original uncomment\n",
    "\n",
    "#lr=0.001\n",
    "pinn_loss_adam_001 = pd.read_csv('pinn_loss_adam.csv')\n",
    "pinn_loss_adam_001 = pinn_loss_adam_001[1:]\n",
    "pinn_loss_adam_001['epoch'] = np.arange(499) + 1\n",
    "pinn_loss_adam_001['loss'] = np.log(pinn_loss_adam_001['loss'])\n",
    "\n",
    "#lr=0.01\n",
    "pinn_loss_adam_01 = pd.read_csv('pinn_loss_lr_0.01_1.3203276.csv')\n",
    "pinn_loss_adam_01 = pinn_loss_adam_01[1:]\n",
    "pinn_loss_adam_01['epoch'] = np.arange(499) + 1\n",
    "pinn_loss_adam_01['loss'] = np.log(pinn_loss_adam_01['loss'])\n",
    "\n",
    "#lr=0.1\n",
    "pinn_loss_adam_1 = pd.read_csv('pinn_loss_lr_0.1_33.41357.csv')\n",
    "pinn_loss_adam_1 = pinn_loss_adam_1[1:]\n",
    "pinn_loss_adam_1['epoch'] = np.arange(499) + 1\n",
    "pinn_loss_adam_1['loss'] = np.log(pinn_loss_adam_1['loss'])\n",
    "\n",
    "\n",
    "pinn_loss_adam_after_lbfgs = pd.read_csv('pinn_loss_adam_after_lbfgs.csv')\n",
    "pinn_loss_adam_after_lbfgs = pinn_loss_adam_after_lbfgs[1:]\n",
    "pinn_loss_adam_after_lbfgs['epoch'] = np.arange(499) + 2\n",
    "pinn_loss_adam_after_lbfgs['loss'] = np.log(pinn_loss_adam_after_lbfgs['loss'])\n",
    "\n",
    "figure_loss_dd = go.Figure()\n",
    "figure_loss_dd.update_layout(\n",
    "    title=\n",
    "    {\n",
    "        'text' : 'Data-driven NN',\n",
    "        'x':0.5,\n",
    "        'xanchor': 'center',\n",
    "        'font' : dict(\n",
    "        family=\"Arial Black\",\n",
    "        size=25,\n",
    "        color=\"black\")\n",
    "    },\n",
    "    xaxis_title=\"epochs\",\n",
    "    yaxis_title=\"MSE loss (log-scale)\"\n",
    ")\n",
    "figure_loss_pinn = go.Figure()\n",
    "figure_loss_pinn.update_layout(\n",
    "    title=\n",
    "    {\n",
    "        'text' : 'Physics Informed NN',\n",
    "        'x':0.5,\n",
    "        'xanchor': 'center',\n",
    "        'font' : dict(\n",
    "        family=\"Arial Black\",\n",
    "        size=25,\n",
    "        color=\"black\")\n",
    "    },\n",
    "    xaxis_title=\"epochs\",\n",
    "    yaxis_title=\"MSE loss (log-scale)\",\n",
    ")\n",
    "\n",
    "opt = 'Adam'\n",
    "lr = 0.001\n",
    "\n",
    "app = JupyterDash(__name__)\n",
    "app.layout = html.Div(\n",
    "    children=[\n",
    "        html.Div(\n",
    "            children=[\n",
    "                html.Div(\n",
    "                    children=[\n",
    "                        dcc.Interval(id=\"animate\", interval=10, max_intervals=499, disabled=True),\n",
    "                        html.H1(children='Select the Optimization',\n",
    "                                                style={\"text-align\": \"center\", 'fontSize': 25, \"font-weight\": \"bold\"}),\n",
    "                        dcc.Dropdown(['Adam', 'Adam + L-BFGS', 'L-BFGS + Adam'], 'Adam', id='opt-dropdown'),\n",
    "                        html.Button(\"Converge\", id=\"play\")\n",
    "                    ], #end here\n",
    "                    style={ \"display\": \"inline-block\", \"width\": \"30%\", 'position': 'relative', 'left': '100px'}\n",
    "                ),\n",
    "                html.Div(\n",
    "                children =[\n",
    "                    html.H1(children='Select the learning rate',\n",
    "                            style={\"text-align\": \"center\", 'fontSize': 25, \"font-weight\": \"bold\"}),\n",
    "                    dcc.Dropdown([0.1, 0.01, 0.001], 0.001, id='lr-dropdown')\n",
    "                ],\n",
    "                style={ \"display\": \"inline-block\", \"width\": \"30%\", 'position': 'relative', 'top': '-73px', 'left': '300px'}) # 'position': 'relative', 'left': '200px'\n",
    "            ]\n",
    "        ),\n",
    "        html.Div(\n",
    "            children=[\n",
    "                html.Div(\n",
    "                    children=[\n",
    "                        dcc.Graph(id = \"fig_loss_dd\", figure=figure_loss_dd)\n",
    "                    ],\n",
    "                    style={\"display\": \"inline-block\", \"width\": \"50%\"},\n",
    "                ),\n",
    "                html.Div(\n",
    "                    children=[\n",
    "                        dcc.Graph(id = \"fig_loss_pinn\", figure=figure_loss_pinn)\n",
    "                    ],\n",
    "                    style={\"display\": \"inline-block\", \"width\": \"50%\"},\n",
    "                )\n",
    "            ]\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "#Define callback to update graph\n",
    "@app.callback(\n",
    "    [Output('fig_loss_dd', 'figure'),\n",
    "     Output('fig_loss_pinn', 'figure')],\n",
    "    [Input(\"animate\", \"n_intervals\"),\n",
    "     Input(\"opt-dropdown\", \"value\"),\n",
    "     Input(\"lr-dropdown\", \"value\")]\n",
    ")\n",
    "def update_figure(interval, opt_value, lr_value):\n",
    "    #print('interval', interval)\n",
    "    global opt, lr\n",
    "    if interval != None:\n",
    "        if opt_value == 'Adam + L-BFGS':\n",
    "            figure_loss_dd.data = []\n",
    "            figure_loss_pinn.data = []\n",
    "            index = interval%499\n",
    "            if index == 0:\n",
    "                index = 499\n",
    "            #print('index', index)\n",
    "            \n",
    "            df = pd.DataFrame()\n",
    "            df_1 = pd.DataFrame()\n",
    "            if lr_value == 0.1:\n",
    "                df = data_loss_adam_1[:index]\n",
    "                df_1 = pinn_loss_adam_1[:index]\n",
    "            elif lr_value == 0.01:\n",
    "                df = data_loss_adam_01[:index]\n",
    "                df_1 = pinn_loss_adam_01[:index]\n",
    "            else:\n",
    "                df = data_loss_adam_001[:index]\n",
    "                df_1 = pinn_loss_adam_001[:index]\n",
    "                \n",
    "            figure_loss_dd.add_trace(go.Scatter(x=df['epoch'], y=df['loss'], mode='lines+markers', marker=dict(color='blue'), name='adam'))\n",
    "            figure_loss_pinn.add_trace(go.Scatter(x=df_1['epoch'], y=df_1['loss'], mode='lines+markers', marker=dict(color='blue'), name='adam'))\n",
    "            \n",
    "            if index == 499:\n",
    "                lbfgs_loss_dd = 0\n",
    "                lbfgs_loss_pinn = 0\n",
    "                if lr_value == 0.1:\n",
    "                    lbfgs_loss_dd = np.log(1.6185334)\n",
    "                    lbfgs_loss_pinn = np.log(33.41357)\n",
    "                elif lr_value == 0.01:\n",
    "                    lbfgs_loss_dd = np.log(7.652751e-07)\n",
    "                    lbfgs_loss_pinn = np.log(1.3203276)\n",
    "                else:\n",
    "                    lbfgs_loss_dd = np.log(2.457717e-05)\n",
    "                    lbfgs_loss_pinn = np.log(0.4065533)\n",
    "                    \n",
    "                figure_loss_dd.add_trace(go.Scatter(x=[499, 500], y=[df['loss'][499], lbfgs_loss_dd], mode='lines+markers', marker=dict(color='red'), name='L-BFGS'))\n",
    "                figure_loss_pinn.add_trace(go.Scatter(x=[499, 500], y=[df_1['loss'][499], lbfgs_loss_pinn], mode='lines+markers', marker=dict(color='red'), name='L-BFGS'))\n",
    "                \n",
    "        if opt_value == 'Adam':\n",
    "            figure_loss_dd.data = []\n",
    "            figure_loss_pinn.data = []\n",
    "            index = interval%499\n",
    "            if index == 0:\n",
    "                index = 499\n",
    "            #print('index', index)\n",
    "            df = pd.DataFrame()\n",
    "            df_1 = pd.DataFrame()\n",
    "            if lr_value == 0.1:\n",
    "                df = data_loss_adam_1[:index]\n",
    "                df_1 = pinn_loss_adam_1[:index]\n",
    "            elif lr_value == 0.01:\n",
    "                df = data_loss_adam_01[:index]\n",
    "                df_1 = pinn_loss_adam_01[:index]\n",
    "            else:\n",
    "                df = data_loss_adam_001[:index]\n",
    "                df_1 = pinn_loss_adam_001[:index]\n",
    "            \n",
    "            figure_loss_dd.add_trace(go.Scatter(x=df['epoch'], y=df['loss'], mode='lines+markers', marker=dict(color='blue'), name='adam'))\n",
    "            figure_loss_pinn.add_trace(go.Scatter(x=df_1['epoch'], y=df_1['loss'], mode='lines+markers', marker=dict(color='blue'), name='adam'))\n",
    "            \n",
    "        if opt_value == 'L-BFGS + Adam':\n",
    "            figure_loss_dd.data = []\n",
    "            figure_loss_pinn.data = []\n",
    "            index = interval%499\n",
    "            if index == 0:\n",
    "                index = 499\n",
    "            #print('index', index)\n",
    "            df = data_loss_adam_after_lbfgs[:index]\n",
    "            df_1 = pinn_loss_adam_after_lbfgs[:index]\n",
    "            \n",
    "            figure_loss_dd.add_trace(go.Scatter(x=[1], y=[np.log(1.4157594e-06)], mode='markers',  marker=dict(size=12, color='red'), name='L-BFGS'))\n",
    "            figure_loss_pinn.add_trace(go.Scatter(x=[1], y=[np.log(0.94217503)], mode='markers', marker=dict(size=12, color='red'), name='L-BFGS'))\n",
    "            \n",
    "            figure_loss_dd.add_trace(go.Scatter(x=df['epoch'], y=df['loss'], mode='lines+markers', marker=dict(color='blue'), name='adam'))\n",
    "            figure_loss_pinn.add_trace(go.Scatter(x=df_1['epoch'], y=df_1['loss'], mode='lines+markers', marker=dict(color='blue'), name='adam'))\n",
    "        \n",
    "            \n",
    "    return figure_loss_dd, figure_loss_pinn\n",
    "\n",
    "@app.callback(\n",
    "    Output('animate', 'n_intervals'),\n",
    "    [Input('opt-dropdown', 'value'),\n",
    "     Input('lr-dropdown', 'value')]\n",
    ")\n",
    "def update_image(opt_value, lr_value):\n",
    "    global opt\n",
    "    opt = opt_value\n",
    "    #print('value', value)\n",
    "    return None\n",
    "\n",
    "@app.callback(\n",
    "    Output(\"animate\", \"disabled\"),\n",
    "    Input(\"play\", \"n_clicks\"),\n",
    "    State(\"animate\", \"disabled\"),\n",
    ")\n",
    "def toggle(n, playing):\n",
    "    if n:\n",
    "        return not playing\n",
    "    return playing\n",
    "        \n",
    "\n",
    "app.run_server(mode='inline', port=3004)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aadb1b0f",
   "metadata": {},
   "source": [
    "Let's analyze the obtained results. From the graphs, it is evident that the learning rate has a similar impact on both networks. Smaller learning rates are preferable, as increasing the learning rate can potentially cause the model to get trapped in local minima. However, one noticeable difference is that the data-driven networks tend to converge faster compared to the PINN, resulting in the PINN models requiring more training epochs. To gain a deeper understanding of the convergence behavior, we plotted the loss landscape for both models. To accomplish this, we perturbed the neural networks in two random orthogonal directions across a specific grid and visualized the corresponding loss. Examining the loss surface, it is apparent that the data-driven network exhibits a steeper landscape in comparison to the PINN. This finding helps explain why the PINN requires more epochs to reach the global minimum. Furthermore, it is worth noting that the loss landscape of PINNs appears smoother compared to that of the data-driven network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "1ef668a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dash is running on http://127.0.0.1:3006/\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:3006/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x28d12237888>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_data = pd.read_csv('x_data_data.csv')\n",
    "Y_data = pd.read_csv('y_data_data.csv')\n",
    "Z_data = pd.read_csv('z_data_data.csv')\n",
    "\n",
    "X_pinn = pd.read_csv('x_data_pinn.csv')\n",
    "Y_pinn = pd.read_csv('y_data_pinn.csv')\n",
    "Z_pinn = pd.read_csv('z_data_pinn.csv')\n",
    "\n",
    "layout_loss = go.Layout(\n",
    "    margin=dict(l=0, r=0, t=50, b=0)\n",
    ")\n",
    "\n",
    "fig_loss_surf_data = go.Figure(data=[go.Surface(z=Z_data, x=X_data, y=Y_data)], layout=layout_loss)\n",
    "fig_loss_surf_pinn = go.Figure(data=[go.Surface(z=Z_pinn, x=X_pinn, y=Y_pinn)], layout=layout_loss)\n",
    "\n",
    "fig_loss_surf_data.update_layout(\n",
    "    title=\n",
    "    {\n",
    "        'text' : 'Data-driven NN',\n",
    "        'x':0.5,\n",
    "        'xanchor': 'center',\n",
    "        'font' : dict(\n",
    "        family=\"Arial Black\",\n",
    "        size=25,\n",
    "        color=\"black\")\n",
    "    },\n",
    "    scene_camera_eye=dict(x=2.07, y=1.08, z=-0.84),\n",
    "    width=480, height=500\n",
    ")\n",
    "\n",
    "fig_loss_surf_data.update_traces(contours_z=dict(show=True, usecolormap=True,\n",
    "                                  highlightcolor=\"limegreen\", project_z=True))\n",
    "\n",
    "fig_loss_surf_pinn.update_traces(contours_z=dict(show=True, usecolormap=True,\n",
    "                                  highlightcolor=\"limegreen\", project_z=True))\n",
    "\n",
    "fig_loss_surf_pinn.update_layout(\n",
    "    title=\n",
    "    {\n",
    "        'text' : 'Physics Informed NN',\n",
    "        'x':0.5,\n",
    "        'xanchor': 'center',\n",
    "        'font' : dict(\n",
    "        family=\"Arial Black\",\n",
    "        size=25,\n",
    "        color=\"black\")\n",
    "    },\n",
    "    width=480, height=500,\n",
    "    scene_camera_eye=dict(x=2.07, y=1.08, z=-0.84)\n",
    ")\n",
    "\n",
    "\n",
    "app = JupyterDash(__name__)\n",
    "app.layout = html.Div(\n",
    "            children=[\n",
    "                html.Div(\n",
    "                    children=[\n",
    "                        dcc.Graph(id = \"fig_loss_surf_data\", figure=fig_loss_surf_data)\n",
    "                    ],\n",
    "                    style={\"display\": \"inline-block\", \"width\": \"50%\"},\n",
    "                ),\n",
    "                html.Div(\n",
    "                    children=[\n",
    "                        dcc.Graph(id = \"fig_loss_surf_pinn\", figure=fig_loss_surf_pinn)\n",
    "                    ],\n",
    "                    style={\"display\": \"inline-block\", \"width\": \"50%\"},\n",
    "                )\n",
    "            ]\n",
    "        )\n",
    "\n",
    "app.run_server(mode='inline', port=3006)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4643c703",
   "metadata": {},
   "source": [
    "## 6. Synergy between Data-driven and Physics Informel ML\n",
    "\n",
    "Previously, we observed that the PINN model could successfully predict the solution of an ODE system without any labeled data points when all the ODE parameters were fixed. However, in practical applications, it is often necessary for the model to predict solutions for a range of parameters that govern the equation. Therefore, we require a parameterized PINN that can be trained for different parameter ranges. Now, let's consider the density as a varying parameter within the range of (800, 1300) and train the PINN accordingly. We can visualize the performance of PINNs with and without data points in the graph below. The checkbox can be used to select the loss function used for training the model, and the slider allows for adjusting the percentage of data points used (when data loss is part of the network loss), increasing or decreasing its value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "750f8cf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dash is running on http://127.0.0.1:3005/\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:3005/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x28d7f2a6a88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from utils import LossSurface\n",
    "\n",
    "name_list = ['0.5data', '0.5pinn', '0.5bc', '0.5data+bc', '0.5bc+pinn', '0.5data+pinn', '0.5data+bc+pinn',\n",
    "             '0.6data', '0.6pinn', '0.6bc', '0.6data+bc', '0.6bc+pinn', '0.6data+pinn', '0.6data+bc+pinn',\n",
    "             '0.7data', '0.7pinn', '0.7bc', '0.7data+bc', '0.7bc+pinn', '0.7data+pinn', '0.7data+bc+pinn',\n",
    "             '0.8data', '0.8pinn', '0.8bc', '0.8data+bc', '0.8bc+pinn', '0.8data+pinn', '0.8data+bc+pinn',\n",
    "             '0.9data', '0.9pinn', '0.9bc', '0.9data+bc', '0.9bc+pinn', '0.9data+pinn', '0.9data+bc+pinn']\n",
    "\n",
    "index=99\n",
    "\n",
    "ground_truth_surface_N = pd.read_csv('loss_csv/ground_truth_surface_N.csv')\n",
    "ground_truth_surface_N = ground_truth_surface_N.set_index('Unnamed: 0')\n",
    "\n",
    "array = ground_truth_surface_N.columns.values\n",
    "array = array.astype(float)\n",
    "ground_truth_surface_N.columns = np.round(array, 4)\n",
    "\n",
    "layout_u = go.Layout(\n",
    "    scene=dict(\n",
    "        xaxis=dict(showgrid=False),\n",
    "        yaxis=dict(showgrid=False),\n",
    "        zaxis=dict(showgrid=False),\n",
    "        camera=dict(up=dict(x=0, y=0, z=1),\n",
    "                    center=dict(x=0, y=0, z=0),\n",
    "                    eye=dict(x=1.0, y=2.6, z=1.0)),\n",
    "        xaxis_title=\"grid-points\",\n",
    "        yaxis_title=\"density\",\n",
    "        zaxis_title=\"velocity\"\n",
    "        ),\n",
    "    margin=dict(l=0, r=0, t=30, b=0),\n",
    "    autosize=False,\n",
    "    width=490,\n",
    "    height=490\n",
    ")\n",
    "\n",
    "layout_N = go.Layout(\n",
    "    scene=dict(\n",
    "        xaxis=dict(showgrid=False),\n",
    "        yaxis=dict(showgrid=False),\n",
    "        zaxis=dict(showgrid=False),\n",
    "        camera=dict(up=dict(x=0, y=0, z=1),\n",
    "                    center=dict(x=0, y=0, z=0),\n",
    "                    eye=dict(x=1.0, y=2.6, z=1.0)),\n",
    "        xaxis_title=\"grid-points\",\n",
    "        yaxis_title=\"density\",\n",
    "        zaxis_title=\"tension\"\n",
    "        ),\n",
    "    margin=dict(l=0, r=0, t=30, b=0),\n",
    "    autosize=False,\n",
    "    width=490,\n",
    "    height=490\n",
    ")\n",
    "\n",
    "# grond truth u\n",
    "ground_truth_surface_u = pd.read_csv('loss_csv/ground_truth_surface_u.csv')\n",
    "ground_truth_surface_u = ground_truth_surface_u.set_index('Unnamed: 0')\n",
    "\n",
    "array_1 = ground_truth_surface_u.columns.values\n",
    "array_1 = array_1.astype(float)\n",
    "ground_truth_surface_u.columns = np.round(array_1, 4)\n",
    "\n",
    "prediction_surface_figure_u = go.Figure(layout=layout_u)\n",
    "prediction_surface_figure_u.add_trace(go.Surface(z=ground_truth_surface_u.values.tolist(),\n",
    "                         x=np.array(ground_truth_surface_u.columns),\n",
    "                         y=np.array(ground_truth_surface_u.index),\n",
    "                         opacity=0.4, colorscale=[[0, 'green'], [1, 'green']],\n",
    "                         showscale=False, name='ground truth', showlegend=False))\n",
    "\n",
    "prediction_surface_figure_u.update_layout(\n",
    "    title=\n",
    "    {\n",
    "        'text' : 'Velocity',\n",
    "        'x':0.5,\n",
    "        'xanchor': 'center',\n",
    "        'font' : dict(\n",
    "        family=\"Arial Black\",\n",
    "        size=22,\n",
    "        color=\"black\")\n",
    "    }\n",
    ")\n",
    "\n",
    "loss_surface = LossSurface()\n",
    "loss_surface.addLossSurfaceTraces(prediction_surface_figure_u, 'u')\n",
    "\n",
    "\n",
    "# grond truth N\n",
    "prediction_surface_figure_N = go.Figure(layout=layout_N)\n",
    "prediction_surface_figure_N.add_trace(go.Surface(z=ground_truth_surface_N.values.tolist(),\n",
    "                         x=np.array(ground_truth_surface_N.columns),\n",
    "                         y=np.array(ground_truth_surface_N.index),\n",
    "                         opacity=0.4, colorscale=[[0, 'green'], [1, 'green']],\n",
    "                         showscale=False, name='ground-truth', showlegend=True))\n",
    "\n",
    "prediction_surface_figure_N.update_layout(\n",
    "    title=\n",
    "    {\n",
    "        'text' : 'Tension',\n",
    "        'x':0.5,\n",
    "        'xanchor': 'center',\n",
    "        'font' : dict(\n",
    "        family=\"Arial Black\",\n",
    "        size=22,\n",
    "        color=\"black\")\n",
    "    }\n",
    ")\n",
    "\n",
    "loss_surface.addLossSurfaceTraces(prediction_surface_figure_N, 'N')\n",
    "\n",
    "app = JupyterDash(__name__)\n",
    "app.layout = app.layout = html.Div(\n",
    "    children=[\n",
    "        html.Div(\n",
    "            children=[\n",
    "                html.Div(\n",
    "                    children=[\n",
    "                        dcc.Checklist(\n",
    "                            id='checklist',\n",
    "                            options=[\n",
    "                                {'label': 'Data Loss', 'value': 'dl'},\n",
    "                                {'label': 'Boundary Loss', 'value': 'bl'},\n",
    "                                {'label': 'PINN Loss', 'value': 'rl'}\n",
    "                            ],\n",
    "                            inline = True,\n",
    "                            style={\"text-align\": \"center\", 'fontSize': 25, \"font-weight\": \"bold\"}\n",
    "                        ),\n",
    "                        html.H1(children='training data points',\n",
    "                                                style={\"text-align\": \"center\", 'fontSize': 21, \"font-weight\": \"bold\"}),\n",
    "                        dcc.Slider(\n",
    "                        id='slider',\n",
    "                        min=0.5,\n",
    "                        max=0.9,\n",
    "                        step=0.1,\n",
    "                        value=0.5,\n",
    "                        marks={\n",
    "                            0.5: '30%',\n",
    "                            0.6: '50%',\n",
    "                            0.7: '70%',\n",
    "                            0.8: '90%',\n",
    "                            0.9: '100%'\n",
    "                            }\n",
    "                        )\n",
    "                    ], #end here\n",
    "                    style={ \"display\": \"inline-block\", \"width\": \"50%\", 'position': 'relative', 'left': '200px'}\n",
    "                )\n",
    "            ]\n",
    "        ),\n",
    "        html.Div(\n",
    "            children=[\n",
    "                html.Div(\n",
    "                    children=[\n",
    "                        dcc.Graph(id = \"fig_u\", figure=prediction_surface_figure_u)\n",
    "                    ],\n",
    "                    style={\"display\": \"inline-block\", \"width\": \"50%\"},\n",
    "                ),\n",
    "                html.Div(\n",
    "                    children=[\n",
    "                        dcc.Graph(id = \"fig_N\", figure=prediction_surface_figure_N)\n",
    "                    ],\n",
    "                    style={\"display\": \"inline-block\", \"width\": \"50%\"},\n",
    "                )\n",
    "            ]\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "@app.callback(\n",
    "    [Output('fig_u', 'figure'),\n",
    "     Output('fig_N', 'figure')],\n",
    "    [Input('checklist', 'value'),\n",
    "     Input('slider', 'value')]\n",
    ")\n",
    "def update_graph(value, slider_value):\n",
    "    global prediction_surface_figure_u, prediction_surface_figure_N, index\n",
    "    #for name in name_list:\n",
    "        #print('name', name)\n",
    "        #prediction_surface_figure.update_traces(visible=False, selector=dict(name=name))\n",
    "        #prediction_surface_figure_u.update_traces(visible=False, selector=dict(name=name))\n",
    "    #print('slider_value', slider_value)\n",
    "    #for i, trace in enumerate(prediction_surface_figure.data):\n",
    "        #print('i', i)\n",
    "        #print('trace', trace.visible)\n",
    "\n",
    "    #prediction_surface_figure.data[0].visible = False\n",
    "\n",
    "    if index < 99:\n",
    "        prediction_surface_figure_u.data[index].visible = False\n",
    "        prediction_surface_figure_N.data[index].visible = False\n",
    "        index = 99\n",
    "\n",
    "    if value != None:\n",
    "        if(len(value) != 0):\n",
    "            index = round((slider_value - 0.5) * 10)\n",
    "            #print('inside index', slider_value - 0.5)\n",
    "            if 'dl' in value:\n",
    "                if 'rl' in value:\n",
    "                    if 'bl' in value:\n",
    "                        #print('data+bc+pinn')\n",
    "                        index = index * 7 + 7\n",
    "                        prediction_surface_figure_u.update_traces(visible=True, selector=dict(name=str(slider_value) + 'data+bc+pinn'))\n",
    "                        prediction_surface_figure_N.update_traces(visible=True, selector=dict(name=str(slider_value) + 'data+bc+pinn'))\n",
    "                    else:\n",
    "                        #print('data+pinn')\n",
    "                        index = index * 7 + 6\n",
    "                        prediction_surface_figure_u.update_traces(visible=True, selector=dict(name=str(slider_value) + 'data+pinn'))\n",
    "                        prediction_surface_figure_N.update_traces(visible=True, selector=dict(name=str(slider_value) + 'data+pinn'))\n",
    "                elif 'bl' in value:\n",
    "                    #print('data+bc')\n",
    "                    index = index * 7 + 4\n",
    "                    prediction_surface_figure_u.update_traces(visible=True, selector=dict(name=str(slider_value) + 'data+bc'))\n",
    "                    prediction_surface_figure_N.update_traces(visible=True, selector=dict(name=str(slider_value) + 'data+bc'))\n",
    "                else:\n",
    "                    #print('data')\n",
    "                    index = index * 7 + 1\n",
    "                    prediction_surface_figure_u.update_traces(visible=True, selector=dict(name=str(slider_value) + 'data'))\n",
    "                    prediction_surface_figure_N.update_traces(visible=True, selector=dict(name=str(slider_value) + 'data'))\n",
    "            elif 'rl' in value:\n",
    "                if 'bl' in value:\n",
    "                    #print('bc+pinn')\n",
    "                    index = index * 7 + 5\n",
    "                    prediction_surface_figure_u.update_traces(visible=True, selector=dict(name=str(slider_value) + 'bc+pinn'))\n",
    "                    prediction_surface_figure_N.update_traces(visible=True, selector=dict(name=str(slider_value) + 'bc+pinn'))\n",
    "                else:\n",
    "                    #print('pinn')\n",
    "                    index = index * 7 + 2\n",
    "                    prediction_surface_figure_u.update_traces(visible=True, selector=dict(name=str(slider_value) + 'pinn'))\n",
    "                    prediction_surface_figure_N.update_traces(visible=True, selector=dict(name=str(slider_value) + 'pinn'))\n",
    "            else:\n",
    "                #print('bc')\n",
    "                index = index * 7 + 3\n",
    "                prediction_surface_figure_u.update_traces(visible=True, selector=dict(name=str(slider_value) + 'bc'))\n",
    "                prediction_surface_figure_N.update_traces(visible=True, selector=dict(name=str(slider_value) + 'bc'))\n",
    "\n",
    "            #print('index', index)\n",
    "\n",
    "    return prediction_surface_figure_u, prediction_surface_figure_N\n",
    "        \n",
    "\n",
    "app.run_server(mode='inline', port=3005)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d3d97d",
   "metadata": {},
   "source": [
    "By utilizing the interactive visualization provided above, we can observe that the performance of PINNs tends to decrease as they are trained on more complex problems. However, this reduction in performance can be mitigated by incorporating labeled data. Both the data loss and the ODE loss serve as regularizers for each other, meaning that they can mutually enhance performance when used together. Furthermore, the visualization demonstrates the existence of synergy between the data-driven and physics-driven aspects of the model, up to a certain extent. This implies that when we have a sufficient amount of data that adequately represents the full variability of the problem being solved, the inclusion of physics-based constraints may no longer provide additional benefits in terms of improving performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b139fdb7",
   "metadata": {},
   "source": [
    "## 7. Model Reliability\n",
    "\n",
    "Now, let's assess the reliability aspect of the models, which is a crucial consideration in AI, as it determines the level of trust users can place in the data. We have conducted evaluations to gauge the models' reliability across various aspects. The performance of both the purely data-driven model and the hybrid data+physics model has been examined in the presence of noisy data, outlier data, and unseen out-of-distribution (OOD) data. To explore these different reliability aspects, please utilize the radio buttons provided. You can switch between the aspects to view the corresponding performance of the models in each scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "da3239b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dash is running on http://127.0.0.1:3007/\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:3007/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x28d11e300c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "orig_data = pd.read_csv('reliability/t_ai_orig_data/data_points.csv') \n",
    "orig_data['density'] = orig_data['density'] * (2000 - 800) + 800\n",
    "orig_data = orig_data[orig_data['density']<=1300]\n",
    "\n",
    "noisy_data = pd.read_csv('reliability/t_ai_noise_data/new_data_points.csv') \n",
    "noisy_data['density'] = noisy_data['density'] * (2000 - 800) + 800\n",
    "noisy_data = noisy_data[noisy_data['density']<=1300]\n",
    "\n",
    "outlier_data = pd.read_csv('reliability/t_ai_outlier_data/data_points.csv') \n",
    "outlier_data['density'] = outlier_data['density'] * (2000 - 800) + 800\n",
    "outlier_data = outlier_data[outlier_data['density']<=1300]\n",
    "\n",
    "ood_data = pd.read_csv('reliability/t_ai_ood_data/data_points.csv') \n",
    "ood_data['density'] = ood_data['density'] * (2000 - 800) + 800\n",
    "ood_data = ood_data[ood_data['density']<=1300]\n",
    "\n",
    "dd_N = pd.read_csv('reliability/orig/N/data_surface.csv')\n",
    "dd_N = dd_N.set_index('Unnamed: 0')\n",
    "dd_noise_N = pd.read_csv('reliability/noise/N/data_surface_new.csv')\n",
    "dd_noise_N = dd_noise_N.set_index('Unnamed: 0')\n",
    "dd_outlier_N = pd.read_csv('reliability/outlier/N/data_surface.csv')\n",
    "dd_outlier_N = dd_outlier_N.set_index('Unnamed: 0')\n",
    "dd_ood_N = pd.read_csv('reliability/ood/N/data_surface.csv')\n",
    "dd_ood_N = dd_ood_N.set_index('Unnamed: 0')\n",
    "\n",
    "pinn_N = pd.read_csv('reliability/orig/N/data_pinn_surface.csv')\n",
    "pinn_N = pinn_N.set_index('Unnamed: 0')\n",
    "pinn_noise_N = pd.read_csv('reliability/noise_pinn/N/data_pinn_surface_new.csv')\n",
    "pinn_noise_N = pinn_noise_N.set_index('Unnamed: 0')\n",
    "pinn_outlier_N = pd.read_csv('reliability/outlier_pinn/N/data_pinn_surface.csv')\n",
    "pinn_outlier_N = pinn_outlier_N.set_index('Unnamed: 0')\n",
    "pinn_ood_N = pd.read_csv('reliability/ood_pinn/N/data_pinn_surface.csv')\n",
    "pinn_ood_N = pinn_ood_N.set_index('Unnamed: 0')\n",
    "\n",
    "layout = go.Layout(\n",
    "    scene=dict(\n",
    "        xaxis=dict(showgrid=False),\n",
    "        yaxis=dict(showgrid=False),\n",
    "        zaxis=dict(showgrid=False),\n",
    "        camera=dict(up=dict(x=0, y=0, z=1),\n",
    "                    center=dict(x=0, y=0, z=0),\n",
    "                    eye=dict(x=0.3, y=2.1, z=0.0)),\n",
    "        xaxis_title=\"grid-points\",\n",
    "        yaxis_title=\"density\",\n",
    "        zaxis_title=\"tension\"\n",
    "        ),\n",
    "    margin=dict(l=0, r=0, t=30, b=0),\n",
    "    autosize=False,\n",
    "    width=490,\n",
    "    height=490\n",
    ")\n",
    "\n",
    "fig_data = go.Figure(layout=layout)\n",
    "fig_data.add_trace(go.Surface(z=ground_truth_surface_N.values.tolist(),\n",
    "                         x=np.array(ground_truth_surface_N.columns),\n",
    "                         y=np.array(ground_truth_surface_N.index),\n",
    "                         opacity=0.4, colorscale=[[0, 'green'], [1, 'green']],\n",
    "                         showscale=False, name='ground-truth', showlegend=True))\n",
    "fig_data.add_trace(go.Surface(z=dd_N.values.tolist(),\n",
    "                         x=np.array(dd_N.columns),\n",
    "                         y=np.array(dd_N.index),\n",
    "                         opacity=0.4, colorscale=[[0, 'red'], [1, 'red']],\n",
    "                         showscale=False, name='dd-nn', showlegend=True))\n",
    "fig_data.add_trace(go.Scatter3d(x=orig_data['grid_points'], y=orig_data['density'], z=orig_data['solution_N'], mode='markers',\n",
    "                               opacity=0.2, marker=dict(size=5, color='black', opacity=1.0), name='training-data'))\n",
    "fig_data.update_layout(\n",
    "    title=\n",
    "    {\n",
    "        'text' : 'Data-driven Network',\n",
    "        'x':0.5,\n",
    "        'xanchor': 'center',\n",
    "        'font' : dict(\n",
    "        family=\"Arial Black\",\n",
    "        size=22,\n",
    "        color=\"black\")\n",
    "    }\n",
    ")\n",
    "\n",
    "fig_data_pinn = go.Figure(layout=layout)\n",
    "fig_data_pinn.add_trace(go.Surface(z=ground_truth_surface_N.values.tolist(),\n",
    "                         x=np.array(ground_truth_surface_N.columns),\n",
    "                         y=np.array(ground_truth_surface_N.index),\n",
    "                         opacity=0.4, colorscale=[[0, 'green'], [1, 'green']],\n",
    "                         showscale=False, name='ground-truth', showlegend=True))\n",
    "fig_data_pinn.add_trace(go.Surface(z=pinn_N.values.tolist(),\n",
    "                         x=np.array(pinn_N.columns),\n",
    "                         y=np.array(pinn_N.index),\n",
    "                         opacity=0.4, colorscale=[[0, 'red'], [1, 'red']],\n",
    "                         showscale=False, name='pinn', showlegend=True))\n",
    "fig_data_pinn.add_trace(go.Scatter3d(x=orig_data['grid_points'], y=orig_data['density'], z=orig_data['solution_N'], mode='markers',\n",
    "                               opacity=0.2, marker=dict(size=5, color='black', opacity=1.0), name='training-data'))\n",
    "fig_data_pinn.update_layout(\n",
    "    title=\n",
    "    {\n",
    "        'text' : 'Hybrid PINN',\n",
    "        'x':0.5,\n",
    "        'xanchor': 'center',\n",
    "        'font' : dict(\n",
    "        family=\"Arial Black\",\n",
    "        size=22,\n",
    "        color=\"black\")\n",
    "    }\n",
    ")\n",
    "\n",
    "app = JupyterDash(__name__)\n",
    "app.layout = app.layout = html.Div(\n",
    "    children=[\n",
    "        html.Div(\n",
    "            children=[\n",
    "                html.Div(\n",
    "                    children=[\n",
    "                        dcc.RadioItems(['Original Data', 'Add Noise to Data', 'Add Outliers','Out of Distribution Data'], 'Original Data',\n",
    "                                       id = 'radio-item',\n",
    "                                      style={\"text-align\": \"center\", 'fontSize': 21, \"font-weight\": \"bold\"}),\n",
    "                        html.H1(children='',\n",
    "                                                style={\"text-align\": \"center\", 'fontSize': 21, \"font-weight\": \"bold\"}),\n",
    "                    ], #end here\n",
    "                    style={ \"display\": \"inline-block\", \"width\": \"50%\", 'position': 'relative', 'left': '200px'}\n",
    "                )\n",
    "            ]\n",
    "        ),\n",
    "        html.Div(\n",
    "            children=[\n",
    "                html.Div(\n",
    "                    children=[\n",
    "                        dcc.Graph(id = \"fig_data\", figure=fig_data)\n",
    "                    ],\n",
    "                    style={\"display\": \"inline-block\", \"width\": \"50%\"},\n",
    "                ),\n",
    "                html.Div(\n",
    "                    children=[\n",
    "                        dcc.Graph(id = \"fig_data_pinn\", figure=fig_data_pinn)\n",
    "                    ],\n",
    "                    style={\"display\": \"inline-block\", \"width\": \"50%\"},\n",
    "                )\n",
    "            ]\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "@app.callback(\n",
    "    [Output('fig_data', 'figure'),\n",
    "     Output('fig_data_pinn', 'figure')],\n",
    "     Input('radio-item', 'value')\n",
    ")\n",
    "def update_rel_graph(value):\n",
    "    #print('value', value)\n",
    "    if value != None:\n",
    "        if value == 'Original Data':\n",
    "            fig_data.data = [fig_data.data[0]]\n",
    "            fig_data.add_trace(go.Surface(z=dd_N.values.tolist(),\n",
    "                         x=np.array(dd_N.columns),\n",
    "                         y=np.array(dd_N.index),\n",
    "                         opacity=0.4, colorscale=[[0, 'red'], [1, 'red']],\n",
    "                         showscale=False, name='dd-nn', showlegend=True))\n",
    "            fig_data.add_trace(go.Scatter3d(x=orig_data['grid_points'], y=orig_data['density'], z=orig_data['solution_N'], mode='markers',\n",
    "                               opacity=0.2, marker=dict(size=5, color='black', opacity=1.0), name='training-data'))\n",
    "            fig_data_pinn.data = [fig_data_pinn.data[0]]\n",
    "            fig_data_pinn.add_trace(go.Surface(z=pinn_N.values.tolist(),\n",
    "                         x=np.array(pinn_N.columns),\n",
    "                         y=np.array(pinn_N.index),\n",
    "                         opacity=0.4, colorscale=[[0, 'red'], [1, 'red']],\n",
    "                         showscale=False, name='pinn', showlegend=True))\n",
    "            fig_data_pinn.add_trace(go.Scatter3d(x=orig_data['grid_points'], y=orig_data['density'], z=orig_data['solution_N'], mode='markers',\n",
    "                               opacity=0.2, marker=dict(size=5, color='black', opacity=1.0), name='training-data'))\n",
    "            \n",
    "    if value == 'Add Noise to Data':\n",
    "            fig_data.data = [fig_data.data[0]]\n",
    "            fig_data.add_trace(go.Surface(z=dd_noise_N.values.tolist(),\n",
    "                         x=np.array(dd_noise_N.columns),\n",
    "                         y=np.array(dd_noise_N.index),\n",
    "                         opacity=0.4, colorscale=[[0, 'red'], [1, 'red']],\n",
    "                         showscale=False, name='dd-nn', showlegend=True))\n",
    "            fig_data.add_trace(go.Scatter3d(x=noisy_data['grid_points'], y=noisy_data['density'], z=noisy_data['solution_N'], mode='markers',\n",
    "                               opacity=0.4, marker=dict(size=5, color='black', opacity=1.0), name='training-data'))\n",
    "            fig_data_pinn.data = [fig_data_pinn.data[0]]\n",
    "            fig_data_pinn.add_trace(go.Surface(z=pinn_noise_N.values.tolist(),\n",
    "                         x=np.array(pinn_noise_N.columns),\n",
    "                         y=np.array(pinn_noise_N.index),\n",
    "                         opacity=0.4, colorscale=[[0, 'red'], [1, 'red']],\n",
    "                         showscale=False, name='pinn', showlegend=True))\n",
    "            fig_data_pinn.add_trace(go.Scatter3d(x=noisy_data['grid_points'], y=noisy_data['density'], z=noisy_data['solution_N'], mode='markers',\n",
    "                               opacity=0.4, marker=dict(size=5, color='black', opacity=1.0), name='training-data'))\n",
    "            \n",
    "    if value == 'Add Outliers':\n",
    "            fig_data.data = [fig_data.data[0]]\n",
    "            fig_data.add_trace(go.Surface(z=dd_outlier_N.values.tolist(),\n",
    "                         x=np.array(dd_outlier_N.columns),\n",
    "                         y=np.array(dd_outlier_N.index),\n",
    "                         opacity=0.4, colorscale=[[0, 'red'], [1, 'red']],\n",
    "                         showscale=False, name='dd-nn', showlegend=True))\n",
    "            fig_data.add_trace(go.Scatter3d(x=outlier_data['grid_points'], y=outlier_data['density'], z=outlier_data['solution_N'], mode='markers',\n",
    "                               opacity=0.5, marker=dict(size=5, color='black', opacity=1.0), name='training-data'))\n",
    "            fig_data_pinn.data = [fig_data_pinn.data[0]]\n",
    "            fig_data_pinn.add_trace(go.Surface(z=pinn_outlier_N.values.tolist(),\n",
    "                         x=np.array(pinn_outlier_N.columns),\n",
    "                         y=np.array(pinn_outlier_N.index),\n",
    "                         opacity=0.4, colorscale=[[0, 'red'], [1, 'red']],\n",
    "                         showscale=False, name='pinn', showlegend=True))\n",
    "            fig_data_pinn.add_trace(go.Scatter3d(x=outlier_data['grid_points'], y=outlier_data['density'], z=outlier_data['solution_N'], mode='markers',\n",
    "                               opacity=0.5, marker=dict(size=5, color='black', opacity=1.0), name='training-data'))\n",
    "            \n",
    "    if value == 'Out of Distribution Data':\n",
    "            fig_data.data = [fig_data.data[0]]\n",
    "            fig_data.add_trace(go.Surface(z=dd_ood_N.values.tolist(),\n",
    "                         x=np.array(dd_ood_N.columns),\n",
    "                         y=np.array(dd_ood_N.index),\n",
    "                         opacity=0.4, colorscale=[[0, 'red'], [1, 'red']],\n",
    "                         showscale=False, name='dd-nn', showlegend=True))\n",
    "            fig_data.add_trace(go.Scatter3d(x=ood_data['grid_points'], y=ood_data['density'], z=ood_data['solution_N'], mode='markers',\n",
    "                               opacity=0.5, marker=dict(size=5, color='black', opacity=1.0), name='training-data'))\n",
    "            fig_data_pinn.data = [fig_data_pinn.data[0]]\n",
    "            fig_data_pinn.add_trace(go.Surface(z=pinn_ood_N.values.tolist(),\n",
    "                         x=np.array(pinn_ood_N.columns),\n",
    "                         y=np.array(pinn_ood_N.index),\n",
    "                         opacity=0.4, colorscale=[[0, 'red'], [1, 'red']],\n",
    "                         showscale=False, name='pinn', showlegend=True))\n",
    "            fig_data_pinn.add_trace(go.Scatter3d(x=ood_data['grid_points'], y=ood_data['density'], z=ood_data['solution_N'], mode='markers',\n",
    "                               opacity=0.5, marker=dict(size=5, color='black', opacity=1.0), name='training-data'))\n",
    "        \n",
    "#     figure_u.data = [figure_u.data[0], figure_u.data[1]]\n",
    "    return fig_data, fig_data_pinn\n",
    "    \n",
    "\n",
    "app.run_server(mode='inline', port=3007)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a27010",
   "metadata": {},
   "source": [
    "From the observations, it is evident that the hybrid PINN model exhibits better performance in handling noisy data, demonstrates robustness against outliers, and performs well on out-of-distribution (OOD) data when compared to the purely data-driven model. This indicates that the trustworthiness of the hybrid PINN model is not solely reliant on the reliability of the training data. By incorporating the governing physics of the problem, the hybrid model gains an additional level of trustability, enabling it to handle various challenging scenarios more effectively. This emphasizes the importance of integrating domain knowledge and physics principles into the model architecture, thereby enhancing its overall reliability and performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8153a15",
   "metadata": {},
   "source": [
    "## References\n",
    "<a id=\"1\">[1]</a>\n",
    "Von Rueden, Laura, et al. \"Informed Machine Learning–A taxonomy and survey of integrating prior knowledge into learning systems.\" IEEE Transactions on Knowledge and Data Engineering 35.1 (2021): 614-633."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1273f19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>\n",
       "code_show=true; \n",
       "function code_toggle() {\n",
       " if (code_show){\n",
       " $('div.input').hide();\n",
       " } else {\n",
       " $('div.input').show();\n",
       " }\n",
       " code_show = !code_show\n",
       "} \n",
       "$( document ).ready(code_toggle);\n",
       "</script>\n",
       "The raw code for this IPython notebook is by default hidden for easier reading.\n",
       "To toggle on/off the raw code, click <a href=\"javascript:code_toggle()\">here</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "HTML('''<script>\n",
    "code_show=true; \n",
    "function code_toggle() {\n",
    " if (code_show){\n",
    " $('div.input').hide();\n",
    " } else {\n",
    " $('div.input').show();\n",
    " }\n",
    " code_show = !code_show\n",
    "} \n",
    "$( document ).ready(code_toggle);\n",
    "</script>\n",
    "The raw code for this IPython notebook is by default hidden for easier reading.\n",
    "To toggle on/off the raw code, click <a href=\"javascript:code_toggle()\">here</a>.''')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
